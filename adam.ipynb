# -*- coding: utf-8 -*-
"""
Created on Fri Apr 22 09:16:34 2022

@author: zzzz
"""

#Afin de mener à bien cette étude sur les optimiseurs fournis par Keras, nous stucturer notre travail comme suit:
#    -Pretraiter et charger les données
#    -Definition du modèle:étant donné qu'il s'agit d'un modèle de reseaux de neuronnes nous allons preciser le nombre de couches cachées et leur taille,la taille d'entrée et de sortie
#    -Perte et optimiseur: Ici nous allons definir la fonction perte de notre taches et specifier les differents optimiseurs à utiliser
#    modèle d'ajustement :il s'agit de l'etape d'apprentissage du reseau de neurones(definition du nombre d'epoques)

from tensorflow import keras
#from tensor.keras import layers
import matplotlib as plt
import numpy as np
import pandas as pd
import sklearn
#importation du dataset(nous utiliserons ici les données simples du classificateur de gamme de prix mobile disponible sur kaggle)
#l'ensemble de données se compose de 20 fonctionnalités et nous devons predire la fourchette de prix dans laquelle se situe le telelophe.Lesquelles sont divisées en 4 classes

dataset = pd.read_csv('train.csv')
dataset.head(10)

#changer le dataframe en tableau numpy
X = dataset.iloc[:,:20].values
Y = dataset.iloc[:,20:21].values

#normalisation des données
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

#Encodage des classes
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder()
Y = ohe.fit_transform(Y).toarray()

#separation des données en apprentissage et en test
from sklearn.model_selection import train_test_split 
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1)

#construction du reseau de neurones
import keras
from keras.models import Sequential
from keras.layers import Dense
model = Sequential() #specifie que nous creons le modèle de facon séquentiel
model.add(Dense(16,input_dim=20,activation='relu'))
model.add(Dense(12,activation='relu'))
model.add(Dense(4,activation='softmax')) #couche de sorie qui prend différentes fontions d'activation mais pour notre cas c'est softmax

#Specifiaction de la fonction de perte et du premier optimiseur

#la perte ici sera une foction d'entropie croisée et les metriques permettent de specifier la facon dont nous voulons evaluer les performances de notre reseau
model.compile(loss = 'categorical_crossentropty',optimiseur = 'adam', metrics = ['accuracy'])
#model de formation
#ici nous specifions le nombre d'epoques,la taille du lot et les données:l'historique se compose de la precision et du modèle après chaque epoque
history = model.fit(X_train,Y_train,epochs = 100,batch_size = 64)

#Verification des performances du modèle sur les données de test
y_pred = model.predict(X_test)
#covertir les predicions en etiquettes
pred=list()
for i in range(len(y_pred)):
    pred.append(np.argmax(y_pred[i]))
#convertir une etiquette pour etiqueter
test = list()
for i in range(len(y_pred)):
    test.append(np.argmax(y_pred[i]))

from sklearn.metrics import accuracy_score
a = accuracy_score(pred,test)
print('la precision est :', a*100)
#visualisation de la foction de perte et de la precision
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('Epoch')
plt.legend(['Train','Test'],loc='upper left')
plt.show()

